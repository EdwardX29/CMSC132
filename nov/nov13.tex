\section{Wednesday, November 13, 2019}
\subsection{Synchronization}
Last time, we introduced threads. To recap, recall that the minimal representation of a thread consists of a stack and a program counter. Just about everything else (including the heap) is shared by all threads. This means that if one thread creates an object in the heap, every other thread can access this object as well. Today, we will talk about the correct way to access data shared between threads since doing so in an unsafe way might corrupt the data being accessed.

In Java, there is a concept of \vocab{thread safe} classes, which means that when threads share an object of this kind, we do not have to worry about corrupting data. Thread safe classes are also commonly referred to as \vocab{synchronized classes} --- synchronization in Java guarantees that no two threads can modify the object at the same time. An example of a synchronized class is the \verb!StringBuffer! class. On the other hand, the \verb!StringBuilder! class is \textbf{not} synchronized; it is not thread safe. In addition, the \verb!ArrayList! and \verb!HashMap! classes are not thread safe.


\subsection{Data Races}

A \vocab{data race} occurs when two or more threads in a single process are accessing the same memory location concurrently, and one of the threads attempts to modify the resource. This ``single resource" can even be a single variable, like an \verb!int! or \verb!ArrayList!. 

In order to better clarify what a data race is, consider the following example:

\begin{lstlisting}
public class DataRace extends Thread {
    static int common = 0;
    public void run() {
        int local = common; // data race
        local = local + 1;
        common = local; // data race
    }
    public static void main(String[] args) throws InterruptedException {
        int max = 3;
        DataRace[] allThreads = new DataRace[max];
        for (int i = 0; i < allThreads.length; i++)
            allThreads[i] = new DataRace();
        for (DataRace thread : allThreads)
            thread.start();
        for (DataRace t : allThreads)
            thread.join();
            System.out.println(common); // may not be 3
        }
    }
\end{lstlisting}

In this example, we create a \verb!run! method that makes a copy of a shared \verb!int! variable into a local variable, increments the local variable, and subsequently sets the shared variable equal to the local variable after incrementation. 

In the \verb!main! method, we create three threads, call \verb!start! on them all, and finally \verb!join! them all. This means that all of the threads have finished executing after the \verb!join! statements. While we would expect the the shared \verb!common! variable to store $3$ after all three threads have finished running (we increment the variable three times). However, it turns out that this is not necessarily the case. 

For example, suppose Thread $1$ successfully increments \verb!common! to $1$, and Thread $2$ is in the process of performing its incrementation. If Thread $2$ executes the statement \verb!int local = common! and the scheduler switches to the third thread, then Thread $3$ may also execute \verb!int local = common!. At this point, when Thread $2$ finishes executing, Thread $3$ will still have the old value of \verb!common!, and the final value of \verb!common! will be $2$ rather than $3$. 

Surprisingly, changing the three lines of code to just \verb!common++! won't fix the problem either --- the problem will just be hidden in assembly code (it won't be as visible to us). Some operations in programming languages run completely independently of other threads (such operations are called \vocab{atomic operations}), but as we've shown, incrementation is not an atomic operation. 

In order to prevent data races, we can use \vocab{locks}, which help enforce synchronization. Locks are entities that can be helped by only one thread at a time, and they help enforce mutual exclusion so that we can protect \vocab{critical sections} of codes (i.e. portions of code that we do not want more than one thread accessing at once). Threads can acquire and release locks, but only one thread can acquire a lock at a time. Other threads must wait to acquire a lock (halting execution) if the lock is held by another thread.

Here is the same code segment that we just saw but now with a lock:

\begin{lstlisting}
public class DataRace extends Thread {
    static int common = 0;
    static Object lockObj = new Object(); // all threads use lockObj’s lock
    public void run() {
        synchronized(lockObj) { // only one thread will be allowed
            int local = common; // data race eliminated
            local = local + 1;
            common = local;
        }
    }
    public static void main(String[] args) {
        …
    }
}
\end{lstlisting}

In this code segment, our critical section is the portion of code in which we're incrementing \verb!common! by one (we only want one thread to execute this portion of code at once). Thus, we are motivated create a lock in order to enforce this policy.

We declare a global variable \verb!lockObj!, which is an \verb!Object!. Since \verb!lockObj! is a global variable, the object is shared between all of the threads. Next, we've placed the critical section in a \verb!synchronized() { ... }! block, which is how we acquire a lock. If a thread begins executing the synchronized block, it acquires the lock specified, and it begins to execute the code in the code block. No other thread can acquire the lock while the thread is executing this code block. After execution, the lock is returned, and other threads are permitted to acquire the block.

It's also important not to place \textit{everything} in a synchronized block -- otherwise, we wouldn't be multithreading at all (only one thread would be able to execute their \verb!run! method at a time). It's also important to remember that threads can be performing different tasks. In our examples